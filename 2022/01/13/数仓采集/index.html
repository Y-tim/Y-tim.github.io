<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>数仓采集平台搭建步骤 |  Y-tim</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 
<script>
var _hmt = _hmt || [];
(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
})();
</script>


      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
      <canvas width="1777" height="841"
        style="position: fixed; left: 0px; top: 0px; z-index: 99999; pointer-events: none;"></canvas>
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-数仓采集"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  数仓采集平台搭建步骤
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/01/13/%E6%95%B0%E4%BB%93%E9%87%87%E9%9B%86/" class="article-date">
  <time datetime="2022-01-13T08:57:14.803Z" itemprop="datePublished">2022-01-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/BigData/">BigData</a> / <a class="article-category-link" href="/categories/BigData/%E6%95%B0%E4%BB%93/">数仓</a> / <a class="article-category-link" href="/categories/BigData/%E6%95%B0%E4%BB%93/%E6%95%B0%E4%BB%93%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%E6%AD%A5%E9%AA%A4/">数仓采集平台搭建步骤</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">5.7k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">30 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="一、服务器准备"><a href="#一、服务器准备" class="headerlink" title="一、服务器准备"></a>一、服务器准备</h2><h3 id="1、-修改静态IP"><a href="#1、-修改静态IP" class="headerlink" title="1、 修改静态IP"></a>1、 修改静态IP</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># vim /etc/sysconfig/network-scripts/ifcfg-ens33</span></span><br><span class="line"></span><br><span class="line">DEVICE=ens33</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">NAME=<span class="string">&quot;ens33&quot;</span></span><br><span class="line">PREFIX=24</span><br><span class="line">IPADDR=192.168.1.102</span><br><span class="line">GATEWAY=192.168.1.2</span><br><span class="line">DNS1=192.168.1.2</span><br></pre></td></tr></table></figure>

<h3 id="2、-修改主机名称"><a href="#2、-修改主机名称" class="headerlink" title="2、 修改主机名称"></a>2、 修改主机名称</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># hostnamectl --static set-hostname hadoop102</span></span><br></pre></td></tr></table></figure>

<h3 id="3、-配置主机名称映射，打开-etc-hosts"><a href="#3、-配置主机名称映射，打开-etc-hosts" class="headerlink" title="3、 配置主机名称映射，打开/etc/hosts"></a>3、 配置主机名称映射，打开/etc/hosts</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># vim /etc/hosts</span></span><br></pre></td></tr></table></figure>

<p>添加如内容</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.100 hadoop100</span><br><span class="line">192.168.1.101 hadoop101</span><br><span class="line">192.168.1.102 hadoop102</span><br><span class="line">192.168.1.103 hadoop103</span><br><span class="line">192.168.1.104 hadoop104</span><br><span class="line">192.168.1.105 hadoop105</span><br><span class="line">192.168.1.106 hadoop106</span><br><span class="line">192.168.1.107 hadoop107</span><br><span class="line">192.168.1.108 hadoop108</span><br></pre></td></tr></table></figure>

<h3 id="4、-关闭防火墙"><a href="#4、-关闭防火墙" class="headerlink" title="4、 关闭防火墙"></a>4、 关闭防火墙</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># systemctl stop firewalld</span></span><br><span class="line">[root@hadoop102 ~]<span class="comment"># systemctl disable firewalld</span></span><br></pre></td></tr></table></figure>

<h3 id="5、-给用户配置root权限"><a href="#5、-给用户配置root权限" class="headerlink" title="5、 给用户配置root权限"></a>5、 给用户配置root权限</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># vim /etc/sudoers</span></span><br></pre></td></tr></table></figure>

<p>修改/etc/sudoers文件，找到下面一行（102行），在%wheel下面添加一行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Allow root to run any commands anywhere</span></span><br><span class="line">root    ALL=(ALL)     ALL</span><br><span class="line">%wheel  ALL=(ALL)       ALL</span><br><span class="line">logan   ALL=(ALL)     NOPASSWD: ALL</span><br></pre></td></tr></table></figure>

<h3 id="6、-SSH免密登录"><a href="#6、-SSH免密登录" class="headerlink" title="6、 SSH免密登录"></a>6、 SSH免密登录</h3><p>生成公钥和私钥</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<p>将公钥拷贝到要免密登录的目标机器上</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 .ssh]$ ssh-copy-id hadoop102[logan@hadoop102 .ssh]$ ssh-copy-id hadoop103[logan@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure>

<h2 id="二、安装JDK"><a href="#二、安装JDK" class="headerlink" title="二、安装JDK"></a>二、安装JDK</h2><h3 id="1、-卸载现有JDK"><a href="#1、-卸载现有JDK" class="headerlink" title="1、 卸载现有JDK"></a>1、 卸载现有JDK</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 opt]<span class="comment"># sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps</span></span><br></pre></td></tr></table></figure>

<h3 id="2、-解压JDK到-opt-module目录下"><a href="#2、-解压JDK到-opt-module目录下" class="headerlink" title="2、 解压JDK到/opt/module目录下"></a>2、 解压JDK到/opt/module目录下</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]<span class="comment"># tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/</span></span><br></pre></td></tr></table></figure>

<h3 id="3、-配置JDK环境变量"><a href="#3、-配置JDK环境变量" class="headerlink" title="3、 配置JDK环境变量"></a>3、 配置JDK环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]<span class="comment"># sudo vim /etc/profile.d/my_env.sh</span></span><br></pre></td></tr></table></figure>

<p>添加如下内容，然后保存（:wq）退出</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_212export PATH=$PATH:$JAVA_HOME/bin</span></span><br></pre></td></tr></table></figure>

<p>让环境变量生效</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ <span class="built_in">source</span> /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>测试JDK是否安装成功</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]<span class="comment"># java -version</span></span><br></pre></td></tr></table></figure>

<p>分发环境变量配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ sudo /home/logan/bin/xsync /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>分别在hadoop103、hadoop104上执行source</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop103 module]$ <span class="built_in">source</span> /etc/profile.d/my_env.sh[logan@hadoop104 module]$ <span class="built_in">source</span> /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<h2 id="三、安装hadoop"><a href="#三、安装hadoop" class="headerlink" title="三、安装hadoop"></a>三、安装hadoop</h2><h3 id="1、-解压安装包"><a href="#1、-解压安装包" class="headerlink" title="1、 解压安装包"></a>1、 解压安装包</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<h3 id="2、-将Hadoop添加到环境变量"><a href="#2、-将Hadoop添加到环境变量" class="headerlink" title="2、 将Hadoop添加到环境变量"></a>2、 将Hadoop添加到环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 hadoop-3.1.3]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>在profile文件末尾添加JDK路径：（shitf+g）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoop-3.1.3export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin</span></span><br></pre></td></tr></table></figure>

<h3 id="3、-分发环境变量文件"><a href="#3、-分发环境变量文件" class="headerlink" title="3、 分发环境变量文件"></a>3、 分发环境变量文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 hadoop-3.1.3]$ sudo /home/logan/bin/xsync /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<h3 id="4、-source-是之生效（3台节点）"><a href="#4、-source-是之生效（3台节点）" class="headerlink" title="4、 source 是之生效（3台节点）"></a>4、 source 是之生效（3台节点）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ <span class="built_in">source</span> /etc/profile.d/my_env.sh[logan@hadoop103 module]$ <span class="built_in">source</span> /etc/profile.d/my_env.sh[logan@hadoop104 module]$ <span class="built_in">source</span> /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<h3 id="5、-配置文件"><a href="#5、-配置文件" class="headerlink" title="5、 配置文件"></a>5、 配置文件</h3><p>core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>	<span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为logan --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>logan<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="comment">&lt;!-- 配置该logansuperUser、允许通过代理访问的主机节点 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.logan.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="comment">&lt;!-- 配置该logansuperUser、允许通过代理用户所属组 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.logan.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="comment">&lt;!-- 配置该logansuperUser、允许通过代理的用户--&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.logan.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>	<span class="comment">&lt;!-- nn web端访问地址--&gt;</span>	<span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    	<span class="comment">&lt;!-- 2nn web端访问地址--&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>        <span class="comment">&lt;!-- 测试环境指定HDFS副本的数量1 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>	<span class="comment">&lt;!-- 指定MR走shuffle --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>        <span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>        <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>        <span class="comment">&lt;!-- yarn容器允许分配的最大最小内存 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>        <span class="comment">&lt;!-- yarn容器允许管理的物理内存大小 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>        <span class="comment">&lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>        <span class="comment">&lt;!-- 开启日志聚集功能 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>          <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span>          <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop102:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>	<span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span>	<span class="tag">&lt;<span class="name">property</span>&gt;</span>    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span>	<span class="tag">&lt;/<span class="name">property</span>&gt;</span>	<span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span>	<span class="tag">&lt;<span class="name">property</span>&gt;</span>    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span>	<span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>workers</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop102hadoop103hadoop104</span><br></pre></td></tr></table></figure>

<h3 id="6、-分发hadoop"><a href="#6、-分发hadoop" class="headerlink" title="6、 分发hadoop"></a>6、 分发hadoop</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/</span><br></pre></td></tr></table></figure>

<h3 id="7、-初始化namenode"><a href="#7、-初始化namenode" class="headerlink" title="7、 初始化namenode"></a>7、 初始化namenode</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 hadoop-3.1.3]$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>

<h3 id="8、-启动hdfs-amp-yarn"><a href="#8、-启动hdfs-amp-yarn" class="headerlink" title="8、 启动hdfs&amp;yarn"></a>8、 启动hdfs&amp;yarn</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh[logan@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<h3 id="补充：集群时间同步"><a href="#补充：集群时间同步" class="headerlink" title="补充：集群时间同步"></a>补充：集群时间同步</h3><h4 id="1）时间服务器配置（必须root用户）"><a href="#1）时间服务器配置（必须root用户）" class="headerlink" title="1）时间服务器配置（必须root用户）"></a>1）时间服务器配置（必须root用户）</h4><p>（0）查看所有节点ntpd服务状态和开机自启动状态</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 ~]$ sudo systemctl status ntpd[logan@hadoop102 ~]$ sudo systemctl is-enabled ntpd</span><br></pre></td></tr></table></figure>

<p>（1）在所有节点关闭ntp服务和自启动</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 ~]$ sudo systemctl stop ntpd[logan@hadoop102 ~]$ sudo systemctl <span class="built_in">disable</span> ntpd</span><br></pre></td></tr></table></figure>

<p>（2）修改hadoop102的ntp.conf配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 ~]$ sudo vim /etc/ntp.conf</span><br></pre></td></tr></table></figure>

<p>修改内容如下</p>
<p>a）修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）</p>
<p>打开配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap为restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span></span><br></pre></td></tr></table></figure>

<p> b）修改2（集群在局域网中，不使用其他互联网上的时间）</p>
<p>关闭配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst为#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst</span><br></pre></td></tr></table></figure>

<p>c）添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server 127.127.1.0fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure>



<p>（3）修改hadoop102的/etc/sysconfig/ntpd 文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 ~]$ sudo vim /etc/sysconfig/ntpd</span><br></pre></td></tr></table></figure>

<p>增加内容如下（让硬件时间与系统时间一起同步）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYNC_HWCLOCK=yes</span><br></pre></td></tr></table></figure>

<p>（4）重新启动ntpd服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 ~]$ sudo systemctl start ntpd</span><br></pre></td></tr></table></figure>

<p>（5）设置ntpd服务开机启动</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 ~]$ sudo systemctl <span class="built_in">enable</span> ntpd</span><br></pre></td></tr></table></figure>

<h4 id="2）其他机器配置（必须root用户）"><a href="#2）其他机器配置（必须root用户）" class="headerlink" title="2）其他机器配置（必须root用户）"></a>2）其他机器配置（必须root用户）</h4><p>（1）在其他机器配置10分钟与时间服务器同步一次</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop103 ~]$ sudo crontab -e</span><br></pre></td></tr></table></figure>

<p>编写定时任务如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/10 * * * * /usr/sbin/ntpdate hadoop102</span><br></pre></td></tr></table></figure>

<p>（2）修改任意机器时间</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop103 ~]$ sudo date -s <span class="string">&quot;2017-9-11 11:11:11&quot;</span></span><br></pre></td></tr></table></figure>

<p>（3）十分钟后查看机器是否与时间服务器同步</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop103 ~]$ sudo date</span><br></pre></td></tr></table></figure>

<p>说明：测试的时候可以将10分钟调整为1分钟，节省时间。</p>
<h3 id="9、-集群数据均衡"><a href="#9、-集群数据均衡" class="headerlink" title="9、 集群数据均衡"></a>9、 集群数据均衡</h3><p>1、  节点间数据均衡</p>
<p>​    不同电脑直接的数据进行均衡</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-balancer.sh -threshold 10</span><br></pre></td></tr></table></figure>

<p>​    默认开启10%</p>
<p>​    停止命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-balancer.sh</span><br></pre></td></tr></table></figure>

<p>2、 磁盘间数据均衡</p>
<p>​    同一台电脑进行均衡</p>
<p>（1）生成均衡计划（我们只有一块磁盘，不会生成计划）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs diskbalancer -plan hadoop103</span><br></pre></td></tr></table></figure>

<p>（2）执行均衡计划</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs diskbalancer -execute hadoop103.plan.json</span><br></pre></td></tr></table></figure>

<p>（3）查看当前均衡任务的执行情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs diskbalancer -query hadoop103</span><br></pre></td></tr></table></figure>

<p>（4）取消均衡任务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs diskbalancer -cancel hadoop103.plan.json</span><br></pre></td></tr></table></figure>

<h3 id="10、-LZO压缩"><a href="#10、-LZO压缩" class="headerlink" title="10、 LZO压缩"></a>10、 LZO压缩</h3><p>添加LZO压缩</p>
<p>将编译好后的hadoop-lzo-0.4.20.jar 放入hadoop-3.1.3/share/hadoop/common/</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 common]$ pwd /opt/module/hadoop-3.1.3/share/hadoop/common[logan@hadoop102 common]$ lshadoop-lzo-0.4.20.jar</span><br></pre></td></tr></table></figure>

<p>同步hadoop-lzo-0.4.20.jar到hadoop103、hadoop104</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 common]$ xsync hadoop-lzo-0.4.20.jar</span><br></pre></td></tr></table></figure>

<p>core-site.xml增加配置支持LZO压缩</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.compression.codecs<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>            org.apache.hadoop.io.compress.GzipCodec,            org.apache.hadoop.io.compress.DefaultCodec,            org.apache.hadoop.io.compress.BZip2Codec,            org.apache.hadoop.io.compress.SnappyCodec,            com.hadoop.compression.lzo.LzoCodec,            com.hadoop.compression.lzo.LzopCodec        <span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.compression.codec.lzo.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.hadoop.compression.lzo.LzoCodec<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>之后分发配置文件并重启集群</p>
<p>给LZO文件添加索引的命令:</p>
<p>jar包名,类名加文件在hdfs上的地址</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-lzo-0.4.20.jar  com.hadoop.compression.lzo.DistributedLzoIndexer /input/bigtable.lzo</span><br></pre></td></tr></table></figure>

<h2 id="四、安装zookeeper"><a href="#四、安装zookeeper" class="headerlink" title="四、安装zookeeper"></a>四、安装zookeeper</h2><h3 id="1、解压安装"><a href="#1、解压安装" class="headerlink" title="1、解压安装"></a>1、解压安装</h3><p>解压Zookeeper安装包到/opt/module/目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ tar -zxvf zookeeper-3.5.7.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>修改/opt/module/apache-zookeeper-3.5.7-bin名称为zookeeper-3.5.7</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ mv apache-zookeeper-3.5.7-bin/ zookeeper-3.5.7</span><br></pre></td></tr></table></figure>

<p>同步/opt/module/zookeeper-3.5.7目录内容到hadoop103、hadoop104</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ xsync zookeeper-3.5.7/</span><br></pre></td></tr></table></figure>

<h3 id="2、配置服务器编号"><a href="#2、配置服务器编号" class="headerlink" title="2、配置服务器编号"></a>2、配置服务器编号</h3><p>在/opt/module/zookeeper-3.5.7/这个目录下创建zkData</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 zookeeper-3.5.7]$ mkdir zkData</span><br></pre></td></tr></table></figure>

<p>在/opt/module/zookeeper-3.5.7/zkData目录下创建一个myid的文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 zkData]$ vi myid</span><br></pre></td></tr></table></figure>

<p>在文件中添加与server对应的编号：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2</span><br></pre></td></tr></table></figure>

<p>拷贝配置好的zookeeper到其他机器上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 zkData]$ xsync myid</span><br></pre></td></tr></table></figure>

<p>并分别在hadoop103、hadoop104上修改myid文件中内容为3、4</p>
<h3 id="3、配置zoo-cfg文件"><a href="#3、配置zoo-cfg文件" class="headerlink" title="3、配置zoo.cfg文件"></a>3、配置zoo.cfg文件</h3><p>重命名/opt/module/zookeeper-3.5.7/conf这个目录下的zoo_sample.cfg为zoo.cfg</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 conf]$ mv zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure>

<p>打开zoo.cfg文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 conf]$ vim zoo.cfg</span><br></pre></td></tr></table></figure>

<p>修改数据存储路径配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/opt/module/zookeeper-3.5.7/zkData#######################cluster##########################server.2=hadoop102:2888:3888server.3=hadoop103:2888:3888server.4=hadoop104:2888:3888</span><br></pre></td></tr></table></figure>

<p>同步zoo.cfg配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 conf]$ xsync zoo.cfg</span><br></pre></td></tr></table></figure>

<h2 id="五、安装kafka"><a href="#五、安装kafka" class="headerlink" title="五、安装kafka"></a>五、安装kafka</h2><h3 id="1、解压安装-1"><a href="#1、解压安装-1" class="headerlink" title="1、解压安装"></a>1、解压安装</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ tar -zxvf kafka_2.11-2.4.1.tgz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>修改解压后的文件名称</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ mv kafka_2.11-2.4.1/ kafka</span><br></pre></td></tr></table></figure>

<p>在/opt/module/kafka目录下创建datas文件夹</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 kafka]$ mkdir datas</span><br></pre></td></tr></table></figure>

<h3 id="2、修改配置文件"><a href="#2、修改配置文件" class="headerlink" title="2、修改配置文件"></a>2、修改配置文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 kafka]$ cd config/[logan@hadoop102 config]$ vim server.properties修改或者增加以下内容：#broker的全局唯一编号，不能重复broker.id=0#kafka运行日志存放的路径log.dirs=/opt/module/kafka/datas#配置连接Zookeeper集群地址zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka</span><br></pre></td></tr></table></figure>

<h3 id="3、添加环境变量"><a href="#3、添加环境变量" class="headerlink" title="3、添加环境变量"></a>3、添加环境变量</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ sudo vim /etc/profile.d/my_env.sh#KAFKA_HOMEexport KAFKA_HOME=/opt/module/kafkaexport PATH=$PATH:$KAFKA_HOME/bin[logan@hadoop102 module]$ source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<h3 id="4、分发文件修改id"><a href="#4、分发文件修改id" class="headerlink" title="4、分发文件修改id"></a>4、分发文件修改id</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ xsync kafka/注意：分发之后记得配置其他机器的环境变量</span><br></pre></td></tr></table></figure>

<p>分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties中的broker.id=1、broker.id=2</p>
<h3 id="5、启动-amp-关闭kafka"><a href="#5、启动-amp-关闭kafka" class="headerlink" title="5、启动&amp;关闭kafka"></a>5、启动&amp;关闭kafka</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 kafka]$ bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties[logan@hadoop102 kafka]$ bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure>

<h3 id="6、常用命令"><a href="#6、常用命令" class="headerlink" title="6、常用命令"></a>6、常用命令</h3><p>1）查看Kafka Topic列表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 kafka]$ bin/kafka-topics.sh --zookeeper hadoop102:2181/kafka --list</span><br></pre></td></tr></table></figure>

<p>2）创建Kafka Topic</p>
<p>进入到/opt/module/kafka/目录下创建日志主题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 kafka]$ bin/kafka-topics.sh --zookeeper hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka  --create --replication-factor 1 --partitions 1 --topic topic_log</span><br></pre></td></tr></table></figure>

<p>3）删除Kafka Topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 kafka]$ bin/kafka-topics.sh --delete --zookeeper hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka --topic topic_log</span><br></pre></td></tr></table></figure>

<p>4）Kafka生产消息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 kafka]$ bin/kafka-console-producer.sh \--broker-list hadoop102:9092 --topic topic_log&gt;hello world&gt;logan  logan</span><br></pre></td></tr></table></figure>

<p>5）Kafka消费消息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 kafka]$ bin/kafka-console-consumer.sh \--bootstrap-server hadoop102:9092 --from-beginning --topic topic_log</span><br></pre></td></tr></table></figure>

<p>–from-beginning：会把主题中以往所有的数据都读取出来。根据业务场景选择是否增加该配置。</p>
<p>6）查看Kafka Topic详情</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 kafka]$ bin/kafka-topics.sh --zookeeper hadoop102:2181/kafka \--describe --topic topic_log</span><br></pre></td></tr></table></figure>

<h2 id="六、安装flume"><a href="#六、安装flume" class="headerlink" title="六、安装flume"></a>六、安装flume</h2><p>解压apache-flume-1.9.0-bin.tar.gz到/opt/module/目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ tar -zxf /opt/software/apache-flume-1.9.0-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>修改apache-flume-1.9.0-bin的名称为flume</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ mv /opt/module/apache-flume-1.9.0-bin /opt/module/flume</span><br></pre></td></tr></table></figure>

<p>将lib文件夹下的guava-11.0.2.jar删除以兼容Hadoop 3.1.3</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ rm /opt/module/flume/lib/guava-11.0.2.jar</span><br></pre></td></tr></table></figure>



<h2 id="七、采集flume的使用"><a href="#七、采集flume的使用" class="headerlink" title="七、采集flume的使用"></a>七、采集flume的使用</h2><p>在/opt/module/flume/job目录下创建file-flume-kafka.conf文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 job]$ vim file-flume-kafka.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#为各组件命名a1.sources = r1a1.channels = c1#描述sourcea1.sources.r1.type = TAILDIRa1.sources.r1.filegroups = f1a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*a1.sources.r1.positionFile = /opt/module/flume/taildir_position.jsona1.sources.r1.interceptors =  i1a1.sources.r1.interceptors.i1.type = com.logan.flume.interceptor.ETLInterceptor$Builder#描述channela1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannela1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092a1.channels.c1.kafka.topic = topic_loga1.channels.c1.parseAsFlumeEvent = false#绑定source和channel以及sink和channel的关系a1.sources.r1.channels = c1</span><br></pre></td></tr></table></figure>

<p>使用的拦截器：<br>依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span>    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flume<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flume-ng-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span>        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span>    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.62<span class="tag">&lt;/<span class="name">version</span>&gt;</span>    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span><span class="tag">&lt;<span class="name">build</span>&gt;</span>    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span>        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span>            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span>            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span>                <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span>                <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span>            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span>        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span>        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span>            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span>                <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span>                    <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span>                <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span>            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span>            <span class="tag">&lt;<span class="name">executions</span>&gt;</span>                <span class="tag">&lt;<span class="name">execution</span>&gt;</span>                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span>                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span>                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span>                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span>                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span>                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span>            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span>        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span>    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>JSONUtils</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.logan.flume.interceptor;<span class="keyword">import</span> com.alibaba.fastjson.JSON;<span class="keyword">import</span> com.alibaba.fastjson.JSONException;<span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JSONUtils</span> </span>&#123;    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isJSONValidate</span><span class="params">(String log)</span></span>&#123;        <span class="keyword">try</span> &#123;            JSON.parse(log);            <span class="keyword">return</span> <span class="keyword">true</span>;        &#125;<span class="keyword">catch</span> (JSONException e)&#123;            <span class="keyword">return</span> <span class="keyword">false</span>;        &#125;    &#125;&#125;</span><br></pre></td></tr></table></figure>

<p>ETLInterceptor</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.logan.flume.interceptor;<span class="keyword">import</span> com.alibaba.fastjson.JSON;<span class="keyword">import</span> org.apache.flume.Context;<span class="keyword">import</span> org.apache.flume.Event;<span class="keyword">import</span> org.apache.flume.interceptor.Interceptor;<span class="keyword">import</span> java.nio.charset.StandardCharsets;<span class="keyword">import</span> java.util.Iterator;<span class="keyword">import</span> java.util.List;<span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ETLInterceptor</span> <span class="keyword">implements</span> <span class="title">Interceptor</span> </span>&#123;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span> </span>&#123;    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> Event <span class="title">intercept</span><span class="params">(Event event)</span> </span>&#123;        <span class="keyword">byte</span>[] body = event.getBody();        String log = <span class="keyword">new</span> String(body, StandardCharsets.UTF_8);        <span class="keyword">if</span> (JSONUtils.isJSONValidate(log)) &#123;            <span class="keyword">return</span> event;        &#125; <span class="keyword">else</span> &#123;            <span class="keyword">return</span> <span class="keyword">null</span>;        &#125;    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> List&lt;Event&gt; <span class="title">intercept</span><span class="params">(List&lt;Event&gt; list)</span> </span>&#123;        Iterator&lt;Event&gt; iterator = list.iterator();        <span class="keyword">while</span> (iterator.hasNext())&#123;            Event next = iterator.next();            <span class="keyword">if</span>(intercept(next)==<span class="keyword">null</span>)&#123;                iterator.remove();            &#125;        &#125;        <span class="keyword">return</span> list;    &#125;    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> <span class="keyword">implements</span> <span class="title">Interceptor</span>.<span class="title">Builder</span></span>&#123;        <span class="meta">@Override</span>        <span class="function"><span class="keyword">public</span> Interceptor <span class="title">build</span><span class="params">()</span> </span>&#123;            <span class="keyword">return</span> <span class="keyword">new</span> ETLInterceptor();        &#125;        <span class="meta">@Override</span>        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;        &#125;    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;    &#125;&#125;</span><br></pre></td></tr></table></figure>

<h2 id="八、消费flume的使用"><a href="#八、消费flume的使用" class="headerlink" title="八、消费flume的使用"></a>八、消费flume的使用</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop104 job]$ vim kafka-flume-hdfs.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">## 组件a1.sources=r1a1.channels=c1a1.sinks=k1## source1a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSourcea1.sources.r1.batchSize = 5000a1.sources.r1.batchDurationMillis = 2000a1.sources.r1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092a1.sources.r1.kafka.topics=topic_loga1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type = com.logan.flume.interceptor.TimeStampInterceptor$Builder## channel1a1.channels.c1.type = filea1.channels.c1.checkpointDir = /opt/module/flume/checkpoint/behavior1a1.channels.c1.dataDirs = /opt/module/flume/data/behavior1/a1.channels.c1.maxFileSize = 2146435071a1.channels.c1.capacity = 1000000a1.channels.c1.keep-alive = 6## sink1a1.sinks.k1.type = hdfsa1.sinks.k1.hdfs.path = /origin_data/gmall/log/topic_log/%Y-%m-%da1.sinks.k1.hdfs.filePrefix = log-a1.sinks.k1.hdfs.round = falsea1.sinks.k1.hdfs.rollInterval = 10a1.sinks.k1.hdfs.rollSize = 134217728a1.sinks.k1.hdfs.rollCount = 0## 控制输出文件是原生文件。a1.sinks.k1.hdfs.fileType = CompressedStreama1.sinks.k1.hdfs.codeC = lzop## 拼装a1.sources.r1.channels = c1a1.sinks.k1.channel= c1</span><br></pre></td></tr></table></figure>

<p>拦截器：TimeStampInterceptor</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.logan.interceptor;<span class="keyword">import</span> com.alibaba.fastjson.JSONObject;<span class="keyword">import</span> org.apache.flume.Context;<span class="keyword">import</span> org.apache.flume.Event;<span class="keyword">import</span> org.apache.flume.interceptor.Interceptor;<span class="keyword">import</span> java.nio.charset.StandardCharsets;<span class="keyword">import</span> java.util.List;<span class="keyword">import</span> java.util.Map;<span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeStampInterceptor</span> <span class="keyword">implements</span> <span class="title">Interceptor</span> </span>&#123;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span> </span>&#123;    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> Event <span class="title">intercept</span><span class="params">(Event event)</span> </span>&#123;        Map&lt;String, String&gt; headers = event.getHeaders();        String log = <span class="keyword">new</span> String(event.getBody(), StandardCharsets.UTF_8);        JSONObject jsonObject = JSONObject.parseObject(log);        String ts = jsonObject.getString(<span class="string">&quot;ts&quot;</span>);        headers.put(<span class="string">&quot;timestamp&quot;</span>, ts);        <span class="keyword">return</span> event;    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> List&lt;Event&gt; <span class="title">intercept</span><span class="params">(List&lt;Event&gt; list)</span> </span>&#123;                <span class="keyword">for</span> (Event event : list) &#123;            intercept(event);        &#125;        <span class="keyword">return</span> list;    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;    &#125;    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> <span class="keyword">implements</span> <span class="title">Interceptor</span>.<span class="title">Builder</span> </span>&#123;        <span class="meta">@Override</span>        <span class="function"><span class="keyword">public</span> Interceptor <span class="title">build</span><span class="params">()</span> </span>&#123;            <span class="keyword">return</span> <span class="keyword">new</span> TimeStampInterceptor();        &#125;        <span class="meta">@Override</span>        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;        &#125;    &#125;&#125;</span><br></pre></td></tr></table></figure>

<h2 id="九、安装MySql"><a href="#九、安装MySql" class="headerlink" title="九、安装MySql"></a>九、安装MySql</h2><h3 id="第一种方式"><a href="#第一种方式" class="headerlink" title="第一种方式"></a>第一种方式</h3><h4 id="1、安装"><a href="#1、安装" class="headerlink" title="1、安装"></a>1、安装</h4><p>卸载自带的Mysql-libs（如果之前安装过mysql，要全都卸载掉）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ rpm -qa | grep -i -E mysql\|mariadb | xargs -n1 sudo rpm -e --nodeps</span><br></pre></td></tr></table></figure>

<p>安装mysql依赖</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ sudo rpm -ivh 01_mysql-community-common-5.7.16-1.el7.x86_64.rpm[logan@hadoop102 software]$ sudo rpm -ivh 02_mysql-community-libs-5.7.16-1.el7.x86_64.rpm[logan@hadoop102 software]$ sudo rpm -ivh 03_mysql-community-libs-compat-5.7.16-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>

<p>安装mysql-client</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ sudo rpm -ivh 04_mysql-community-client-5.7.16-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>

<p>安装mysql-server</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ sudo rpm -ivh 05_mysql-community-server-5.7.16-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>

<p>启动mysql</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ sudo systemctl start mysqld</span><br></pre></td></tr></table></figure>

<p>查看mysql密码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ sudo cat /var/log/mysqld.log | grep password</span><br></pre></td></tr></table></figure>

<h4 id="2、配置"><a href="#2、配置" class="headerlink" title="2、配置"></a>2、配置</h4><p>1）用刚刚查到的密码进入mysql（如果报错，给密码加单引号）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ mysql -uroot -p&#x27;password&#x27;</span><br></pre></td></tr></table></figure>

<p>2）设置复杂密码(由于mysql密码策略，此密码必须足够复杂)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set password=password(&quot;Qs23=zs32&quot;);</span><br></pre></td></tr></table></figure>

<p>3）更改mysql密码策略</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global validate_password_length=4;mysql&gt; set global validate_password_policy=0;</span><br></pre></td></tr></table></figure>

<p>4）设置简单好记的密码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set password=password(&quot;123456&quot;);</span><br></pre></td></tr></table></figure>

<p>5）进入msyql库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use mysql</span><br></pre></td></tr></table></figure>

<p>6）查询user表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select user, host from user;</span><br></pre></td></tr></table></figure>

<p>7）修改user表，把Host表内容修改为%</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update user set host=&quot;%&quot; where user=&quot;root&quot;;</span><br></pre></td></tr></table></figure>

<p>8）刷新</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; flush privileges;</span><br></pre></td></tr></table></figure>

<p>9）退出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; quit;</span><br></pre></td></tr></table></figure>

<h3 id="第二种方式"><a href="#第二种方式" class="headerlink" title="第二种方式"></a>第二种方式</h3><h4 id="1、安装前"><a href="#1、安装前" class="headerlink" title="1、安装前"></a>1、安装前</h4><p>卸载之前存在的mysql</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ rpm -qa | grep -i -E mysql\|mariadb | xargs -n1 sudo rpm -e --nodeps</span><br></pre></td></tr></table></figure>

<p>删除相关的文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find / -name mysql</span><br></pre></td></tr></table></figure>

<h4 id="2、安装mysql"><a href="#2、安装mysql" class="headerlink" title="2、安装mysql"></a>2、安装mysql</h4><p>1.2.1 下面mysql官网提供的mysql repo源<br> centos的yum 源中默认是没有mysql的，所以我们需要先去官网下载mysql的repo源并安装；</p>
<p>mysql官网下载链接：mysql repo下载地址 如下：<a target="_blank" rel="noopener" href="https://dev.mysql.com/downloads/">https://dev.mysql.com/downloads/</a></p>
<h5 id="下载软件包rpm文件"><a href="#下载软件包rpm文件" class="headerlink" title="下载软件包rpm文件"></a>下载软件包rpm文件</h5><p>文件下载到Centos/usr/local/mysql文件夹下；</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/localmkdir mysqlcd mysqlwget  https://repo.mysql.com//mysql80-community-release-el7-1.noarch.rpm</span><br></pre></td></tr></table></figure>

<h5 id="安装-yum-repo文件并更新-yum-缓存；"><a href="#安装-yum-repo文件并更新-yum-缓存；" class="headerlink" title="安装 yum repo文件并更新 yum 缓存；"></a>安装 yum repo文件并更新 yum 缓存；</h5><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh mysql57-community-release-el7-<span class="number">11</span><span class="selector-class">.noarch</span><span class="selector-class">.rpm</span></span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<p>会在/etc/yum.repos.d/目录下生成两个repo文件mysql-community.repo mysql-community-source.repo</p>
<p>更新 yum 命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum clean allyum makecache</span><br></pre></td></tr></table></figure>

<h5 id="使用-yum安装mysql"><a href="#使用-yum安装mysql" class="headerlink" title="使用 yum安装mysql"></a>使用 yum安装mysql</h5><p>当我们在使用yum安装mysql时，yum默认会从yum仓库中安装mysql最新的GA版本；如何选择自己的版本；</p>
<p>第一步： 查看mysql yum仓库中mysql版本，使用如下命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum repolist all | grep mysql</span><br></pre></td></tr></table></figure>

<p>可以看到 MySQL 5.5 5.6 5.7为禁用状态 而MySQL 8.0为启用状态；</p>
<p>第二步 使用 yum-config-manager 命令修改相应的版本为启用状态最新版本为禁用状态，根据需要安装的版本修改</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager --<span class="built_in">disable</span> mysql80-community <span class="comment">#关闭8.0版本yum-config-manager --enable mysql57-community #开启5.7版本</span></span><br></pre></td></tr></table></figure>

<p>或者可以编辑 mysql repo文件，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/yum.repos.d/mysql-community.repo </span><br></pre></td></tr></table></figure>

<p>将相应版本下的enabled改成 1 即可；</p>
<h5 id="安装mysql-命令如下："><a href="#安装mysql-命令如下：" class="headerlink" title="安装mysql 命令如下："></a>安装mysql 命令如下：</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install mysql-community-server</span><br></pre></td></tr></table></figure>

<h5 id="开启mysql-服务"><a href="#开启mysql-服务" class="headerlink" title="开启mysql 服务"></a>开启mysql 服务</h5><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start mysqld<span class="selector-class">.service</span></span><br></pre></td></tr></table></figure>

<h5 id="获取初始密码登录mysql"><a href="#获取初始密码登录mysql" class="headerlink" title="获取初始密码登录mysql"></a>获取初始密码登录mysql</h5><p>mysql在安装后会创建一个root@locahost账户，并且把初始的密码放到了/var/log/mysqld.log文件中；</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /var/log/mysqld.log | grep password</span><br></pre></td></tr></table></figure>

<p>使用初始密码登录mysql</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p  <span class="comment">#会提示输入密码</span></span><br></pre></td></tr></table></figure>

<h4 id="修改初始密码："><a href="#修改初始密码：" class="headerlink" title="修改初始密码："></a>修改初始密码：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER USER <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED BY <span class="string">&#x27;MyNewPass4!&#x27;</span>;<span class="comment">#注意位数和种类至少大+写+小写+符号+数字</span></span><br></pre></td></tr></table></figure>

<h4 id="忘记密码重置密码"><a href="#忘记密码重置密码" class="headerlink" title="忘记密码重置密码"></a>忘记密码重置密码</h4><p>[重置密码解决MySQL for Linux错误 ERROR 1045 (28000): Access denied for user ‘root‘@’localhost’ (using password: YES)]</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/my.cnf <span class="comment">#注：windows下修改的是my.iniskip-grant-tables# 在[mysqld]后面任意一行添加skip-grant-tables用来跳过密码验证的过程;设置完密码记得删除systemctl restart mysqld.service #重启mysql ，就可以免密码登陆了，然后进行修改密码</span></span><br></pre></td></tr></table></figure>



<h2 id="十、安装sqoop"><a href="#十、安装sqoop" class="headerlink" title="十、安装sqoop"></a>十、安装sqoop</h2><p>解压sqoop安装包到指定目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ tar -zxf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>修改解压内容的名称</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 module]$ mv sqoop-1.4.6.bin__hadoop-2.0.4-alpha/ sqoop</span><br></pre></td></tr></table></figure>

<p>进入到/opt/module/sqoop/conf目录，重命名配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 conf]$ mv sqoop-env-template.sh sqoop-env.sh</span><br></pre></td></tr></table></figure>

<p>修改配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 conf]$ vim sqoop-env.sh</span><br></pre></td></tr></table></figure>

<p>增加如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_COMMON_HOME=/opt/module/hadoop-3.1.3export HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3export HIVE_HOME=/opt/module/hiveexport ZOOKEEPER_HOME=/opt/module/zookeeper-3.5.7export ZOOCFGDIR=/opt/module/zookeeper-3.5.7/conf</span><br></pre></td></tr></table></figure>

<p>拷贝JDBC驱动</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ cp mysql-connector-java-5.1.27-bin.jar /opt/module/sqoop/lib/</span><br></pre></td></tr></table></figure>

<h2 id="十一、安装hive"><a href="#十一、安装hive" class="headerlink" title="十一、安装hive"></a>十一、安装hive</h2><h3 id="1、安装-1"><a href="#1、安装-1" class="headerlink" title="1、安装"></a>1、安装</h3><p>解压apache-hive-3.1.2-bin.tar.gz到/opt/module/目录下面</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ tar -zxvf /opt/software/apache-hive-3.1.2-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>修改apache-hive-3.1.2-bin.tar.gz的名称为hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ mv /opt/module/apache-hive-3.1.2-bin/ /opt/module/hive</span><br></pre></td></tr></table></figure>

<p>修改/etc/profile.d/my_env.sh，添加环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>添加内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#HIVE_HOMEexport HIVE_HOME=/opt/module/hiveexport PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure>

<p>使环境变量生效</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 software]$ source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>解决日志Jar包冲突，进入/opt/module/hive/lib目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 lib]$ mv log4j-slf4j-impl-2.10.0.jar log4j-slf4j-impl-2.10.0.jar.bak</span><br></pre></td></tr></table></figure>

<h3 id="2、配置-1"><a href="#2、配置-1" class="headerlink" title="2、配置"></a>2、配置</h3><p>在$HIVE_HOME/conf目录下新建hive-site.xml文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 conf]$ vim hive-site.xml`</span><br></pre></td></tr></table></figure>

<p>添加如下内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop102:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    <span class="tag">&lt;<span class="name">property</span>&gt;</span>        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    <span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="3、初始化元数据库"><a href="#3、初始化元数据库" class="headerlink" title="3、初始化元数据库"></a>3、初始化元数据库</h3><p>1）登陆MySQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 conf]$ mysql -uroot -p123456</span><br></pre></td></tr></table></figure>

<p>2）新建Hive元数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database metastore;mysql&gt; quit;</span><br></pre></td></tr></table></figure>

<p>3）初始化Hive元数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[logan@hadoop102 conf]$ schematool -initSchema -dbType mysql -verbose</span><br></pre></td></tr></table></figure>



 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://ylxlogan.top/2022/01/13/%E6%95%B0%E4%BB%93%E9%87%87%E9%9B%86/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E4%BB%93/" rel="tag">数仓</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2022/01/13/%E6%95%B0%E4%BB%93%E8%84%9A%E6%9C%AC/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            数仓脚本
          
        </div>
      </a>
    
    
      <a href="/2022/01/12/%E6%95%B0%E4%BB%93%E5%8E%9F%E7%90%86/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">数仓原理</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "GrJ0j9xyLU5BKd9RsgY4Xsub-gzGzoHsz",
    app_key: "JHTKI05eA7ieHmjdXeBqTVfz",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2022
        <i class="ri-heart-fill heart_icon"></i> Y-tim
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/logal.jpg" alt="Y-tim"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->
 
<script src="/js/clickBoom2.js"></script>
 
<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->
 
<script src="/js/dz.js"></script>
 
<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>